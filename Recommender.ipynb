{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "grand-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tools\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "convinced-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "little-benefit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is ../data\n"
     ]
    }
   ],
   "source": [
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "golden-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "executed-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-winter",
   "metadata": {},
   "source": [
    "## Ratings dataset\n",
    "\n",
    "We will train the recommender system on the dataset in which element consists of three values:\n",
    "* `user_id` - id of the user (the smallest user id is 1)\n",
    "* `item_id` - id of the movie (the smallest item id is 1)\n",
    "* `rating` - rating given by the user to the item (ratings are integer numbers between 1 and 5.\n",
    "\n",
    "The recommender system need to predict the rating for any given pair of `user_id` and `item_id`.\n",
    "\n",
    "We measure the quality of the predicted ratings using the mean-squared error (MSE) loss:\n",
    "$$\n",
    "  \\frac{1}{N}\\sum_{i=1}^N (r_i - \\hat{r}_i)^2\n",
    "$$\n",
    "where $r_i$ is a real rating and $\\hat{r}_i$ is a predicted one.\n",
    "\n",
    "Note: The predicted rating $\\hat{r}_i$ does not have to be an integer number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nervous-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = data.RatingsData(root=data_dir, train=True)\n",
    "testset = data.RatingsData(root=data_dir, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "better-receiver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id=1, item_id=1, rating=5\n"
     ]
    }
   ],
   "source": [
    "# Print one sample from the dataset\n",
    "x = trainset[0]\n",
    "print(f'user_id={x[0]}, item_id={x[1]}, rating={x[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-sleeve",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "digital-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderSystem(nn.Module):\n",
    "    def __init__(self, n_users, n_items):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_users: Number of users.\n",
    "          n_items: Number of items.\n",
    "        \"\"\"\n",
    "\n",
    "        super(RecommenderSystem, self).__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users + 1, 150)\n",
    "        self.item_factors = torch.nn.Embedding(n_items + 1, 150)\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(300, 100)\n",
    "        self.linear2 = torch.nn.Linear(100, 200)\n",
    "        self.linear3 = torch.nn.Linear(200, 300)\n",
    "        self.linear4 = torch.nn.Linear(300, 1)\n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.drop1 = nn.Dropout(0.25, inplace=False)\n",
    "        self.drop2 = nn.Dropout(0.5, inplace=False)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          user_ids of shape (batch_size): User ids (starting from 1).\n",
    "          item_ids of shape (batch_size): Item ids (starting from 1).\n",
    "        \n",
    "        Returns:\n",
    "          outputs of shape (batch_size): Predictions of ratings.\n",
    "        \"\"\"\n",
    "        users = self.user_factors(user_ids)\n",
    "        items = self.item_factors(item_ids)\n",
    "        x = torch.cat([users, items], 1)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = self.linear3(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        x = self.linear4(x)\n",
    " \n",
    "        output_scores = x.reshape(user_ids.shape,)\n",
    "        return output_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "piano-communications",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_RecommenderSystem_shapes():\n",
    "    n_users, n_items = 100, 1000\n",
    "    model = RecommenderSystem(n_users, n_items)\n",
    "    batch_size = 10\n",
    "    user_ids = torch.arange(1, batch_size+1)\n",
    "    item_ids = torch.arange(1, batch_size+1)\n",
    "    output = model(user_ids, item_ids)\n",
    "    print(output.shape)\n",
    "    assert output.shape == torch.Size([batch_size]), \"Wrong output shape.\"\n",
    "    print('Success')\n",
    "\n",
    "test_RecommenderSystem_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-burner",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "descending-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = RecommenderSystem(trainset.n_users, trainset.n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "duplicate-blogger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "idx: 0   , loss: 12.3753, total loss: 12.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\optim\\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "<ipython-input-25-3b33b724455d>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x1 = torch.tensor(train_x1).to(torch.int64)\n",
      "<ipython-input-25-3b33b724455d>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x2 = torch.tensor(train_x2).to(torch.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 150 , loss: 1.3742, total loss: 422.234\n",
      "idx: 300 , loss: 1.4101, total loss: 625.304\n",
      "idx: 450 , loss: 1.1810, total loss: 808.322\n",
      "idx: 600 , loss: 0.9938, total loss: 974.587\n",
      "idx: 750 , loss: 0.6937, total loss: 1135.558\n",
      "idx: 900 , loss: 1.0839, total loss: 1296.309\n",
      "idx: 1050, loss: 1.2932, total loss: 1459.452\n",
      "idx: 1200, loss: 0.9339, total loss: 1626.622\n",
      "idx: 1350, loss: 1.0662, total loss: 1787.373\n",
      "idx: 1500, loss: 0.7451, total loss: 1941.752\n",
      "idx: 1650, loss: 1.1000, total loss: 2104.211\n",
      "idx: 1800, loss: 0.7744, total loss: 2258.031\n",
      "idx: 1950, loss: 0.8082, total loss: 2408.667\n",
      "idx: 2100, loss: 0.9202, total loss: 2562.647\n",
      "idx: 2250, loss: 1.2715, total loss: 2713.372\n",
      "idx: 2400, loss: 0.8182, total loss: 2853.710\n",
      "Epoch: 1\n",
      "idx: 0   , loss: 0.6948, total loss: 2952.246\n",
      "idx: 150 , loss: 1.2432, total loss: 3092.088\n",
      "idx: 300 , loss: 1.4424, total loss: 3233.282\n",
      "idx: 450 , loss: 1.0280, total loss: 3370.393\n",
      "idx: 600 , loss: 0.6641, total loss: 3511.745\n",
      "idx: 750 , loss: 1.1221, total loss: 3653.451\n",
      "idx: 900 , loss: 0.9578, total loss: 3791.477\n",
      "idx: 1050, loss: 0.6673, total loss: 3930.782\n",
      "idx: 1200, loss: 0.5088, total loss: 4070.123\n",
      "idx: 1350, loss: 1.0399, total loss: 4211.271\n",
      "idx: 1500, loss: 1.0431, total loss: 4353.043\n",
      "idx: 1650, loss: 0.6979, total loss: 4488.738\n",
      "idx: 1800, loss: 1.1180, total loss: 4624.433\n",
      "idx: 1950, loss: 0.7828, total loss: 4764.133\n",
      "idx: 2100, loss: 0.7067, total loss: 4901.536\n",
      "idx: 2250, loss: 1.4132, total loss: 5038.791\n",
      "idx: 2400, loss: 0.8798, total loss: 5172.560\n",
      "Epoch: 2\n",
      "idx: 0   , loss: 0.8373, total loss: 5262.086\n",
      "idx: 150 , loss: 1.0896, total loss: 5391.071\n",
      "idx: 300 , loss: 0.8012, total loss: 5515.693\n",
      "idx: 450 , loss: 0.6534, total loss: 5648.459\n",
      "idx: 600 , loss: 0.7036, total loss: 5775.867\n",
      "idx: 750 , loss: 0.8779, total loss: 5902.835\n",
      "idx: 900 , loss: 0.6702, total loss: 6025.955\n",
      "idx: 1050, loss: 1.1790, total loss: 6155.730\n",
      "idx: 1200, loss: 0.8080, total loss: 6283.699\n",
      "idx: 1350, loss: 1.1347, total loss: 6414.317\n",
      "idx: 1500, loss: 0.7453, total loss: 6540.538\n",
      "idx: 1650, loss: 1.1724, total loss: 6670.692\n",
      "idx: 1800, loss: 0.9255, total loss: 6799.129\n",
      "idx: 1950, loss: 1.4902, total loss: 6923.969\n",
      "idx: 2100, loss: 0.9432, total loss: 7055.985\n",
      "idx: 2250, loss: 0.8890, total loss: 7187.142\n",
      "idx: 2400, loss: 0.8541, total loss: 7321.849\n",
      "Epoch: 3\n",
      "idx: 0   , loss: 0.5975, total loss: 7413.105\n",
      "idx: 150 , loss: 0.6087, total loss: 7538.581\n",
      "idx: 300 , loss: 1.0196, total loss: 7664.454\n",
      "idx: 450 , loss: 0.6901, total loss: 7791.729\n",
      "idx: 600 , loss: 0.9095, total loss: 7914.288\n",
      "idx: 750 , loss: 0.5697, total loss: 8039.059\n",
      "idx: 900 , loss: 0.6301, total loss: 8156.334\n",
      "idx: 1050, loss: 0.8705, total loss: 8277.288\n",
      "idx: 1200, loss: 0.6190, total loss: 8403.115\n",
      "idx: 1350, loss: 0.6711, total loss: 8531.118\n",
      "idx: 1500, loss: 0.3870, total loss: 8658.157\n",
      "idx: 1650, loss: 1.0659, total loss: 8780.791\n",
      "idx: 1800, loss: 1.3101, total loss: 8909.534\n",
      "idx: 1950, loss: 0.9246, total loss: 9033.760\n",
      "idx: 2100, loss: 0.9300, total loss: 9158.787\n",
      "idx: 2250, loss: 0.9778, total loss: 9284.217\n",
      "idx: 2400, loss: 0.7280, total loss: 9406.836\n",
      "Epoch: 4\n",
      "idx: 0   , loss: 0.7557, total loss: 9491.185\n",
      "idx: 150 , loss: 0.9323, total loss: 9613.958\n",
      "idx: 300 , loss: 0.9992, total loss: 9740.506\n",
      "idx: 450 , loss: 1.0800, total loss: 9863.217\n",
      "idx: 600 , loss: 0.8136, total loss: 9986.762\n",
      "idx: 750 , loss: 0.7193, total loss: 10111.297\n",
      "idx: 900 , loss: 0.5892, total loss: 10232.014\n",
      "idx: 1050, loss: 0.8575, total loss: 10350.895\n",
      "idx: 1200, loss: 0.7987, total loss: 10471.097\n",
      "idx: 1350, loss: 0.8687, total loss: 10596.514\n",
      "idx: 1500, loss: 0.7748, total loss: 10716.555\n",
      "idx: 1650, loss: 0.8159, total loss: 10838.573\n",
      "idx: 1800, loss: 0.6782, total loss: 10965.775\n",
      "idx: 1950, loss: 0.6503, total loss: 11084.288\n",
      "idx: 2100, loss: 0.8602, total loss: 11207.914\n",
      "idx: 2250, loss: 0.7876, total loss: 11333.070\n",
      "idx: 2400, loss: 0.6208, total loss: 11457.176\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)   \n",
    "\n",
    "if not skip_training:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.95)\n",
    "    epochs = 5\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch: {}'.format(epoch))\n",
    "        for idx, (train_x1, train_x2, train_label) in enumerate(trainloader):\n",
    "            scheduler.step()\n",
    "            train_x1 = torch.tensor(train_x1).to(torch.int64)\n",
    "            train_x2 = torch.tensor(train_x2).to(torch.int64)\n",
    "            optimizer.zero_grad()\n",
    "            predict_y = model.forward(train_x1, train_x2)\n",
    "            loss = criterion(predict_y, train_label.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            if idx % 150 == 0:\n",
    "                print('idx: {:<4}, loss: {:.4f}, total loss: {:.3f}'.format(idx, loss, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alert-exploration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8628)\n"
     ]
    }
   ],
   "source": [
    "def compute_loss(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for i, (x1, x2, y) in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward(x1, x2)\n",
    "            loss = F.mse_loss(outputs, y)\n",
    "            total_loss = total_loss + loss\n",
    "    a = total_loss/(i)\n",
    "    return a\n",
    "if not skip_training:\n",
    "    print(compute_loss(model, testloader)) # 0.8575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acting-console",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to recsys.pth.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk\n",
    "if not skip_training:\n",
    "    tools.save_model(model, 'recsys.pth', confirm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "asian-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    model = RecommenderSystem(trainset.n_users, trainset.n_items)\n",
    "    tools.load_model(model, 'recsys.pth', device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
